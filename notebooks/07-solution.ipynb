{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d41ad29b-d5ee-4fa2-9698-9e199c262b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a253c-a878-4179-b2cb-be1954bc9757",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Для данных о погоде создать категорию \"время года\" и закодировать ее при помощи OneHotEncoder. Проще всего применить OneHotEncoder при помощи `pandas.get_dummies()`\n",
    "\n",
    "Преобразовать данные о температуре двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a2e0413-f2b6-4548-9c76-8188917f3295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>autumn</th>\n",
       "      <th>spring</th>\n",
       "      <th>summer</th>\n",
       "      <th>winter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>-11</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>-11</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-05</th>\n",
       "      <td>-12</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             t  month  season  autumn  spring  summer  winter\n",
       "Day                                                          \n",
       "2008-01-01   0      1  winter       0       0       0       1\n",
       "2008-01-02  -5      1  winter       0       0       0       1\n",
       "2008-01-03 -11      1  winter       0       0       0       1\n",
       "2008-01-04 -11      1  winter       0       0       0       1\n",
       "2008-01-05 -12      1  winter       0       0       0       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/weather.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "mapper = {\n",
    "    1: 'winter',\n",
    "    2: 'winter',\n",
    "    3: 'spring',\n",
    "    4: 'spring',\n",
    "    5: 'spring',\n",
    "    6: 'summer',\n",
    "    7: 'summer',\n",
    "    8: 'summer',\n",
    "    9: 'autumn',\n",
    "    10: 'autumn',\n",
    "    11: 'autumn',\n",
    "    12: 'winter'\n",
    "}\n",
    "\n",
    "df['month'] = df.index.month\n",
    "df['season'] = df['month'].map(mapper)\n",
    "pd.concat([df, pd.get_dummies(df['season'])], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4748f-cba5-4553-a6d9-062216e6aedb",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Перебрать параметры `n_estimators`, `criterion` и `max_depth` и найти оптимальные. \n",
    "\n",
    "Для решения можно написать тройной цикл, в каждом из которых можно перебирать значения параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e173a80-effb-4f66-a581-69c23e0a6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "x = data.data\n",
    "y = data.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce25fb48-6964-4fb6-b77c-ad0611d0e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_of_model(x_train, y_train, x_test, y_test, n_estimators, criterion, max_depth):\n",
    "    \"\"\"Функция принимает на вход треин и тест выборки и параметры модели. На выходе дает accuracy.\"\"\"\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001c158-71e6-455b-8baa-08e8ef383b7d",
   "metadata": {},
   "source": [
    "**Вариант 1. Перебираем в тройном цикле**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4d8e3b1-7b6b-4790-9c0e-fec204df0143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96, (100, 'entropy', 10))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [5, 100, 300, 500]\n",
    "criterions = ['gini', 'entropy']\n",
    "max_depths = [3, 5, 7, 10]\n",
    "\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "# Ваш код здесь\n",
    "for n in n_estimators:\n",
    "    for criterion in criterions:\n",
    "        for max_depth in max_depths:\n",
    "            acc = get_accuracy_of_model(x_train, y_train, x_test, y_test, n, criterion, max_depth)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_params = (n, criterion, max_depth)\n",
    "\n",
    "best_acc, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c7f42-487f-4369-9657-9eaba577a8df",
   "metadata": {},
   "source": [
    "**Вариант 2. Генерируем сетку и перебираем по ней**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27ced7a4-50bc-4dd1-953a-8ae2874340d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96, (100, 'entropy', 10))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "for (n, criretion, max_depth) in itertools.product(n_estimators, criterions, max_depths):\n",
    "    acc = get_accuracy_of_model(x_train, y_train, x_test, y_test, n, criterion, max_depth)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_params = (n, criterion, max_depth)\n",
    "        \n",
    "best_acc, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c0f3c-ff18-4e17-8351-3ad87789c537",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Построить модель SGDClassifier и осуществить подбор гиперпараметров при помощи случайного поиска (список гиперпараметров можно посмотреть в документации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19bbee81-31ba-4f91-8f1c-6c6ac329b52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, max_iter=100, penalty='elasticnet')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.00001, 0.0001, 0.1],\n",
    "    'max_iter': [100, 1000, 2000],\n",
    "    'eta0': [0, 0.1, 0.0001]\n",
    "}\n",
    "\n",
    "r_search = RandomizedSearchCV(SGDClassifier(), params)\n",
    "r_search.fit(x_train, y_train)\n",
    "r_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2fc6491-74e5-4103-9ad0-a6ef50a62c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547046674927715"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33005d7e-7038-4e91-86f8-a1673cce2bbe",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Обучить модель градиентного бустинга на датасете, провести подбор гиперпараметров (взять любые 3 штуки, их список можно получить через документацию к модели).\n",
    "\n",
    "Сравнить качество с полученными ранее результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06193ad2-951f-4bc7-9844-9b720d9f1c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 310, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 10 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.44839047 0.10839047        nan        nan 0.9494947\n",
      " 0.96435633        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'learning_rate': [0.0001, 0.00001, 0.0001, 0.1],\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [2, 3, 5]\n",
    "}\n",
    "\n",
    "r_search = RandomizedSearchCV(GradientBoostingClassifier(), params)\n",
    "r_search.fit(x_train, y_train)\n",
    "r_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193c2cc-fedc-4d77-bc66-07bf9c658c60",
   "metadata": {},
   "source": [
    "В warning сказано, что 30 из 50 моделей не смогли обучиться, потому что лосс-функция `exponential` работает только с бинарной классификацией. Можно убрать подбор по лоссу, и тогда отработает быстрее и качественнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d4c1b37-f892-4a19-8ed0-9d56c51897b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9643563265868099"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f9bf4d-a13d-4cdd-adca-a715d97daa8d",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Иногда нужно использовать модели, у которых интерфейс отличается от интерфейса моделей из sklearn и тогда приходится самостоятельно реализовывать стекинг.\n",
    "\n",
    "Задача \n",
    "\n",
    "Алгоритм построения стекинга:\n",
    "- Получить прогнозы базовых моделей\n",
    "- Использовать прогнозы базовых моделей в качестве признаков для финализирующей модели\n",
    "- Оформить модель в отдельную функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72834ac1-2db6-4dff-90b9-f82f9ecdde93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x):\n",
    "    return (x - x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85780a7f-c721-47a8-af45-0a1b9f792f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models(x_train, y_train, models):\n",
    "    \"\"\"Обучаем модели\"\"\"\n",
    "    for model in models:\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "def predict_base_models(x, models):\n",
    "    \"\"\"Предсказываем и нормируем прогнозы\"\"\"\n",
    "    res = []\n",
    "    for model in models:\n",
    "        res.append(model.predict(x))\n",
    "    base_predictions = np.array(res).T\n",
    "    # Некоторые модели чувствительны к тому, чтобы на входе были нормированные данные\n",
    "    return preprocess_data(base_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ea61805-cea5-4f9c-9e50-cc097443020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stacking(x_train, y_train, models, final_model):\n",
    "    fit_models(x_train, y_train, models)\n",
    "    final_features = predict_base_models(x_train, models)\n",
    "    final_model.fit(final_features, y_train)\n",
    "    return models, final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a00738-7f17-499d-9ace-1055de7f67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stacking(x, models, final_model):\n",
    "    final_features = predict_base_models(x, models)\n",
    "    return final_model.predict(final_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab4479-6501-450a-a91f-0b46b0d1fff3",
   "metadata": {},
   "source": [
    "Для лучшей сходимости методов преобразуем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59c99233-27be-4d8b-88ea-102efa7ac99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess_data(x_train)\n",
    "x_test = preprocess_data(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1225d-62e1-496b-85a2-dbcb58848810",
   "metadata": {},
   "source": [
    "Используем модели из предыдущих заданий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39baad43-05a7-49e3-83cb-24f27c201084",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=10),\n",
    "    SGDClassifier(eta0=0.0001, max_iter=1000, penalty='elasticnet'),\n",
    "    \n",
    "]\n",
    "final_model = LogisticRegression(max_iter=1000)\n",
    "models, final_model = fit_stacking(x_train, y_train, models, final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf0089b3-fcbb-4eab-a50e-9e764b36921e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688888888888889"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_stacking(x_test, models, final_model)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11673346-2c12-404a-80b0-eefc852030ac",
   "metadata": {},
   "source": [
    "Точность немного выше, чем было до этого"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
