{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e352a138-c91c-415a-9be1-c72675714985",
   "metadata": {},
   "source": [
    "# Машинное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d559d054-9e98-46be-8175-5e02ad9eca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684d423-f121-480b-a3a6-d23b72fa3d12",
   "metadata": {},
   "source": [
    "## Предобработка данных\n",
    "\n",
    "### Работа с пропусками с категориальными данными\n",
    "\n",
    "- заменить на \"неизвестно\"\n",
    "- заменить наиболее популярным значением\n",
    "- дропнуть\n",
    "\n",
    "### Работа с пропусками с числовыми данными\n",
    "\n",
    "- заменить на среднее значение\n",
    "- `ffill`/`bfill`/`interpolate`, где это имеет смысл (например, во временных рядах)\n",
    "- дропнуть\n",
    "\n",
    "\n",
    "### Нормализация числовых признаков\n",
    "\n",
    "- привести к диапазону от 0 до 1 по формуле\n",
    "\n",
    "$x_{new} = \\frac{x - x_{min}}{x_{max} - x_{min}}$\n",
    "\n",
    "- вычесть среднее и разделить на среднеквадратичное отклонение\n",
    "\n",
    "$x_{new} = \\frac{x - x_{mean}}{\\sigma}$\n",
    "\n",
    "### Обработка категориальных признаков\n",
    "\n",
    "- OneHotEncoding - заменяем колонку с $n$ значениями на $n$ колонок, в каждой из которых стоит 0 или 1, в зависимости от того, принадлежит ли объект этой категории. Универсальный способ, но значительно увеличивает размерность в данных (нужно много данных, чтобы модель хорошо обучилась).\n",
    "- Закодировать категорию от 1 до n. Хорошо сработает, если категории можно упорядочить (например, год выпуска машины, грейд работника) или если всего две категории (например, пол) и нет смысла добавлять вторую колонку как в one hot encoding.\n",
    "- Не используем категориальный признак\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2c946-13f8-49e9-8034-9852c9d6f4d6",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Для данных о погоде создать категорию \"время года\" и закодировать ее при помощи OneHotEncoder. Проще всего применить OneHotEncoder при помощи `pandas.get_dummies()`\n",
    "\n",
    "Преобразовать данные о температуре двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a7bd004-0c00-44b3-8cd1-33194a1993f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blue  green  red\n",
       "0     1      0    0\n",
       "1     0      0    1\n",
       "2     1      0    0\n",
       "3     0      0    1\n",
       "4     0      1    0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример\n",
    "\n",
    "series = pd.Series(['blue', 'red', 'blue', 'red', 'green'])\n",
    "pd.get_dummies(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a951c7e-20b5-49ef-9c6e-c0ad54e536fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4ec7f-b374-4643-850c-564e8c59afcc",
   "metadata": {},
   "source": [
    "## Модель случайного леса\n",
    "\n",
    "Обучим 100 деревьев решений на разных подмножествах обучающей выборки (выбирая для каждого дерева случайные строки и столбцы из $X$). \n",
    "\n",
    "Ответ будем получать голосованием.\n",
    "\n",
    "Например, за то, что объект принадлежит классу 1 проголосовало 90 деревьев, а за то, что объект принадлежит классу 2, проголосовало 10 деревьев. Итого - берем ответ 1.\n",
    "\n",
    "Такая модель называется моделью случайного леса\n",
    "\n",
    "Основные аргументы:\n",
    "\n",
    "- `n_estimators` - максимальное число деревьев в лесу\n",
    "- `criterion` - критерий для создания узла: или критерий Джини gini (по умолчанию), или энтропия entropy.\n",
    "- `max_depth` - максимальная глубина дерева\n",
    "- `max_features` - максимальное число атрибутов, которые будут проверены при создании узла, по умолчанию это равно корню квадратному из числа всех атрибутов в данных.\n",
    "- `max_samples` - максимальное число примеров используемых для одного дерева (примеры выбираются случайно).\n",
    "\n",
    "\n",
    "Сам объект RandomForestClassifier имеет поля:\n",
    "\n",
    "- `estimators_` - список объектов деревьев (типа DecisionTreeClassifier) в этом лесу\n",
    "- `classes_` - метки классов\n",
    "- `n_classes_` - число классов\n",
    "- `n_features_` - число атрибутов\n",
    "- `n_outputs_` - число выходов\n",
    "- `feature_importances_` - оценка важности атрибутов. Очень полезные сведения, показывающие какой вклад дает тот или иной атрибут в точность решения задачи. Полезно, например, для существенного уменьшения размера дерева: удалив атрибуты с малой важностью не сильно потеряем в точности. Полезно и для интерпретируемости результатов. Вычисляется как суммарная величина уменьшения критерия неопределенности для этого атрибута."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "453fcde7-909b-4c97-973d-a0a224173609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b126af0-42da-4a71-b47e-930afbb3793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "x = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf1abf6-2be3-4607-a7ff-c5321cc65ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89196a6-c473-4deb-bec1-4ba6600e79f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711111111111111"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baada061-c776-403d-82fd-51533edbd660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 40,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 49,  0,  1,  0,  0,  2,  0],\n",
       "       [ 0,  0,  0,  0, 45,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 42,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0, 45,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0, 42,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  1,  0,  0, 44,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  3,  0, 43]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee773b9a-5186-46ad-b48e-9851b4168333",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Перебрать параметры `n_estimators`, `criterion` и `max_depth` и найти оптимальные. \n",
    "\n",
    "Для решения можно написать тройной цикл, в каждом из которых можно перебирать значения параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e445aacb-8dff-4545-8972-817cc8d7a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_of_model(x_train, y_train, x_test, y_test, n_estimators, criterion, max_depth):\n",
    "    \"\"\"Функция принимает на вход треин и тест выборки и параметры модели. На выходе дает accuracy.\"\"\"\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2abee29-c580-4889-b19a-9df1c2e69935",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [5, 100, 300, 500]\n",
    "criterions = ['gini', 'entropy']\n",
    "max_depths = [3, 5, 7, 10]\n",
    "\n",
    "# Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e23bf5-d776-4913-ab70-3348f4af3b4b",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров модели\n",
    "\n",
    "Иногда нужно перебирать множество параметров и не хочется писать много циклов. Для таких случаев в sklearn реализован `GridSearchCV` и `RandomSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1baecd8e-7e70-4398-af44-9460559b1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04f12f36-44c4-4483-aff5-d6181bdd35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [5, 100, 500, 1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a87040ca-18b3-4c39-83e4-29450e3a4e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=1000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "search = GridSearchCV(RandomForestClassifier(), params)\n",
    "search.fit(x_train, y_train)\n",
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcdb0406-e1f8-45c6-82c2-1cb8d20e4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=1000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "r_search = RandomizedSearchCV(RandomForestClassifier(), params)\n",
    "r_search.fit(x_train, y_train)\n",
    "r_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f66000-1059-47bf-b7ed-64eae1e8fb45",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Построить модель SGDClassifier и осуществить подбор гиперпараметров при помощи случайного поиска (список гиперпараметров можно посмотреть в документации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71a7def6-2ff4-404c-8207-bbf267236c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3136c1c-91b8-4d06-8ecd-991f169da05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e7764-8925-499c-82f6-4832661b4a07",
   "metadata": {},
   "source": [
    "## Ансамблевые модели\n",
    "\n",
    "Объединяя множество простых моделей в одну сложную, можно получить результат гораздо лучше.\n",
    "\n",
    "Есть несколько способов создания ансамблей:\n",
    "\n",
    "- **Бэггинг** (Bagging, сокращение от Bootstrap Aggregation) - однородные модели (из одного класса) обучаются независимо друг от друга на разных случайных подвыборках и разных признаках. Итоговый прогноз считается при помощи голосования моделей. Пример: случайный лес\n",
    "- **Бустинг** - однородные модели строятся последовательно, каждая следующая модель старается минимизировать ошибку предыдущей. Пример: градиентный бустинг\n",
    "- **Стекинг** - разнородные модели обучаются на всех данных (или на подвыборках) и поверх них строится модель, которая минимизирует общую ошибку.\n",
    "\n",
    "На основе стекинга можно строить очень сложные модели, которые будут долго обучаться и иметь очень высокую точность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86431f81-6311-4682-a125-d0e9ce5d4ceb",
   "metadata": {},
   "source": [
    "## Градиентный бустинг\n",
    "\n",
    "Идея бустинга заключается в следующем:\n",
    "\n",
    "* Пусть мы имеем входы $X$ и указания учителя $Y$.\n",
    "* Обучим первую модель на этих данных, если модель простая,  то обучение будет не очень точным и выход модели будет $F1$, а должны были получить $Y$\n",
    "* Обучим вторую модель на тех же данных, но для нее указания учителя сделаем $Y-F1$, получим выход $F2$, который тоже может отличаться от желаемого. \n",
    "* тогда обучим третью модель, для которой указания учителя будут $Y-F2$, получим выход $F3$.\n",
    "* будем продолжать обучать все новые и новые модели, пока не надоест или пока не достигнем хорошего обучения или других критериев останова. \n",
    "* Результат ансамбля, выход $F=F1+F2+F3+...$\n",
    "\n",
    "Если внимательно присмотреться, то величина $(Y - F1)$ это градиент по $F1$ (со знаком минус) от средневквадратичной ошибки \\\\(0.5*(Y-F1)^2\\\\), потому такой бустинг называют [\"градиентный бустинг\"](https://en.wikipedia.org/wiki/Gradient_boosting), а величины $(Y - F1)$ - \"остатками\" (residuals). \n",
    "\n",
    "Обычно для градиентного бустинга используют следующие библиотеки:\n",
    "\n",
    "- XGBoost\n",
    "- CatBoost\n",
    "- LightGBM\n",
    "\n",
    "В классе мы будем использовать реализацию в sklearn, а в домашней работе предлагаю использовать XGBoost или любую другую реализацию из этих трех."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009415e3-2f80-4f47-baaa-93e1c81b0309",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Обучить модель градиентного бустинга на датасете, провести подбор гиперпараметров (взять любые 3 штуки, их список можно получить через документацию к модели).\n",
    "\n",
    "Сравнить качество с полученными ранее результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "385a784b-d8e8-4319-95f5-1f3729ce1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a135cb-5af0-4d90-a44b-64ce176350e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ddebee-e309-4a48-aa39-1655d354f27f",
   "metadata": {},
   "source": [
    "## Стекинг\n",
    "\n",
    "В случае, когда разные модели совершают разные ошибки, можно использовать стекинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b994f0c1-1494-4cf6-a560-f49e97da723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "estimators = [\n",
    "    ('LogReg', LogisticRegression()),\n",
    "    ('Tree', DecisionTreeClassifier())\n",
    "]\n",
    "clf=StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe56975-148d-4208-b836-b511d4d6d69a",
   "metadata": {},
   "source": [
    "## Задача \n",
    "\n",
    "Добавить в стекинг еще несколько классификаторов (можно взять классификаторы из прошлых заданий) и получить финальный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637e8e1-825e-4bdd-8bb4-7e16a674d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50ffba6-d244-45ae-8591-276c201f24f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Задача\n",
    "\n",
    "Иногда нужно использовать модели, у которых интерфейс отличается от интерфейса моделей из sklearn и тогда приходится самостоятельно реализовывать стекинг.\n",
    "\n",
    "Задача \n",
    "\n",
    "Алгоритм построения стекинга:\n",
    "- Получить прогнозы базовых моделей\n",
    "- Использовать прогнозы базовых моделей в качестве признаков для финализирующей модели\n",
    "- Оформить модель в отдельную функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8a393-4a28-45bc-8357-82893458de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d406943-b64e-4901-9b66-5fa893041e78",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Построить стекинговую регрессионную модель для данных о стоимости домов. Подобрать гиперпараметры для каждой базовой модели, оценить финальное качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b779b59f-ac73-4e81-8804-ea336d933405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    " \n",
    "# Ваш код здесь\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df15b5-0719-44bf-817c-4dfaf404dd1a",
   "metadata": {},
   "source": [
    "# Домашняя работа\n",
    "\n",
    "Будем работать с датасетом подержанных машин https://www.kaggle.com/adityadesai13/used-car-dataset-ford-and-mercedes.\n",
    "\n",
    "Задача - построить прогноз цены машины по ее данным (год выпуска, пробег, расход, размер двигателя, тип коробки передач и тд). \n",
    "\n",
    "Это задача регрессии, поэтому нужно использовать модели регрессоры, а не классификаторы (например, не `StackingClassifier`, а `StackingRegressor`).\n",
    "\n",
    "## Easy\n",
    "\n",
    "Взять один файл с маркой машины.\n",
    "\n",
    "Построить прогноз, используя модели линейной регрессии и случайного леса. Сравнить результаты, используя кросс-валидацию. Подобрать гиперпараметры моделей (для линейной регрессии можно использовать реализацию с градиентным спуском `SGDRegressor`). Оценить качество, используя метрику `r2_score`. Оценить важность признаков (параметр `feature_importance_` у случайного леса).\n",
    "\n",
    "## Normal\n",
    "\n",
    "Объединить в один датафрейм данные по всем маркам машин. Преобразовать категориальные признаки.\n",
    "\n",
    "Построить еще несколько моделей, используя подбор гиперпараметров. Сравнить между собой все построенные модели.\n",
    "\n",
    "## Hard\n",
    "\n",
    "Построить модель стекинга над всеми моделями из задачи Normal + добавить один из градиентных бустингов XGBoost/LightGBM/CatBoost, если они не использовались. Удалось ли улучшить результат?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705001b-3f3b-4609-b1be-a91f414d5095",
   "metadata": {},
   "source": [
    "# Полезные ссылки\n",
    "\n",
    "- [Наивный байесовский классификатор](http://datareview.info/article/6-prostyih-shagov-dlya-osvoeniya-naivnogo-bayesovskogo-algoritma-s-primerom-koda-na-python/)\n",
    "- [AdaBoost](https://habr.com/ru/company/otus/blog/503888/)\n",
    "- [K ближайших соседей (kNN)](https://habr.com/ru/post/149693/)\n",
    "- [Метод опорных векторов (SVM)](https://habr.com/ru/post/105220/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
